---
title: Truthseekers
excerpt: |-
  (Note: This article is translated from <a href="http://www.geekonomics10000.com/458" target="_blank">真理追求者</a>)

  There is a cute <em>problem</em> with all of us. We tend to argue on things that are just distantly related to our own benefit, like whether the democracy system of the US suits China, whether String Theory is a good physics theory, or whether team Argentina could be the champion of this World Cup. The ending of this type of argument are often ungratifying, where the participants' view stays as it initially was - unchanged, and they hardly ever make any compromises on their opinions.<b>
  </b>

  Everyone thinks that he's thinking in a way specific to the topic - instead of dependent of who he's arguing with. Everyone thinks he is truthful in the process of the argument. Is this actually the case?

  Nobel Prize winner Robert Aumann published a thesis in 1976 called "<a href="http://www.econ.brown.edu/Students/Debipriya_Chatterjee/EC2060page/Readings/Aumann76.pdf" target="_blank">Agreeing to Disagree</a>"; this thesis is so influential that it's considered a masterpiece. The thesis says, "it's impossible". If two rational and truthful Truthseekers are engaged in an argument, the outcome of the argument should always be an agreement between the two. In other words, if the argument leaves both sides unconvinced, then there must be a side that is hypocritical instead of truthful.

  This is a slightly surprising statement. Let me first make a quote from Aumann:
wordpress_id: 634
wordpress_url: http://blog.easoncxz.com/?p=634
date: '2013-06-08 21:37:45 +1200'
date_gmt: '2013-06-08 09:37:45 +1200'
categories:
- translate
tags: []
comments:
- id: 1123
  author: 同人于野
  author_email: geekonomics10000@gmail.com
  author_url: http://www.geekonomics10000.com
  date: '2013-06-09 19:29:30 +1200'
  date_gmt: '2013-06-09 07:29:30 +1200'
  content: 一个巨大的惊喜。你的翻译提升了我的原文。
- id: 1126
  author: Eason Chen
  author_email: easoncxz@gmail.com
  author_url: ''
  date: '2013-06-10 16:07:54 +1200'
  date_gmt: '2013-06-10 04:07:54 +1200'
  content: 其实嘛，本人读的书少，不知道「古龙式的争论」其实是什么意思，于是只好选择跳过不译了…
---
<p>(Note: This article is translated from <a href="http://www.geekonomics10000.com/458" target="_blank">真理追求者</a>)</p>
<p>There is a cute <em>problem</em> with all of us. We tend to argue on things that are just distantly related to our own benefit, like whether the democracy system of the US suits China, whether String Theory is a good physics theory, or whether team Argentina could be the champion of this World Cup. The ending of this type of argument are often ungratifying, where the participants' view stays as it initially was - unchanged, and they hardly ever make any compromises on their opinions.<b><br />
</b></p>
<p>Everyone thinks that he's thinking in a way specific to the topic - instead of dependent of who he's arguing with. Everyone thinks he is truthful in the process of the argument. Is this actually the case?</p>
<p>Nobel Prize winner Robert Aumann published a thesis in 1976 called "<a href="http://www.econ.brown.edu/Students/Debipriya_Chatterjee/EC2060page/Readings/Aumann76.pdf" target="_blank">Agreeing to Disagree</a>"; this thesis is so influential that it's considered a masterpiece. The thesis says, "it's impossible". If two rational and truthful Truthseekers are engaged in an argument, the outcome of the argument should always be an agreement between the two. In other words, if the argument leaves both sides unconvinced, then there must be a side that is hypocritical instead of truthful.</p>
<p>This is a slightly surprising statement. Let me first make a quote from Aumann:<a id="more"></a><a id="more-634"></a></p>
<blockquote><p>If two people have the same priors, and their posteriors for an event A are common knowledge, then these posteriors are equal.</p></blockquote>
<p>The are many professional terms in the above quote, e.g. "priors", "posteriors", “common knowledge" etc.. It seems like all of them needs a bit of studying from a layman. Aumann stated in his thesis very humbly that he felt very diffident when he submitted his findings, because the math involved was too trivial. I have never seen anyone use the word "diffidence" to describe his own work; instead, most people boast about how important their research is. In the actual case, it would be quite hard to understand Aumann's thesis without a certain level of understanding of maths.</p>
<p>With the assistance of a <a href="http://hanson.gmu.edu/deceive.pdf" target="_blank">review written by a successor</a>, I can briefly understand what Aumann is saying. If you and I have a mutually consistent understanding of common soccer theory, i.e. if you think Messi plays an important role in team Argentina, and I think so too, it is considered that our "priors" are the same. Think of the two of us being like two computers - if we were provided with exactly the same input, we could produce the exact same output.</p>
<p>From now on, for explaining easily, let's say the World Cup final is Argentina versus Italy. The day before the match, if I announce that I believe Argentina will be the winner, while you announce that you believe Italy will be the winner, then both of us will have <em>shown our sides</em>. This means not only that you know my opinion, but also that I know that you know my opinion, and also that you know that I know that you know my opinion, ... In this way, our opinions are defined as "common knowledge".</p>
<p>The amazing thing about Aumann's mathematical theorem is that - <span style="color: #ff0000;">it being unnecessary for me to tell you why I believe Argentina is going to win, and in the same way, it being unnecessary for you to tell me why you believe Italy is going to win, the two of us can already be able to eventually reach an agreement on "which team is going to be the champion"!</span></p>
<p>The argument between us simplifies to something like this:</p>
<p style="padding-left: 30px;">me: "I believe Argentina is going to win the cup tomorrow."<br />
you: "Understood. But I believe Italy is going to win."<br />
me: "Copy that. But I <i>still</i> believe that it's Argentina."<br />
you: "Italy."<br />
me: "Argentina."<br />
you: "Italy."<br />
me: "alright, Italy it is."</p>
<p>And that's how we reached agreement.</p>
<p>When I first said that I believe Argentina will be the winner, you should already have known that I would only make that claim when I have mastered some pre-match information, for example I have made some in-depth analysis of and comparison between the capabilities of the two teams. But when you raised a disagreement in spite of hearing my claim, I know that you possessed some even-stronger information or evidence, e.g. you discovered through the grapevine that Messi is badly injured and wouldn't be able to play. I wouldn't be sure of specifically what information it is that you possess, but judging by your confidence I would know that your information must be strong. And therefore in this case if I still insist it's Argentina, you should know that what I know is even more convincing, e.g. that the referee is <em>biased towards</em> Argentina. So on and so forth, after a few rounds when you are still insisting it is Italy that would win, I would be convinced that the strength of evidence you possess should be indubitable, hence deciding to agree with you.</p>
<p>For two rational men, that type of discussion would be sufficient to lead to an agreement. Furthermore, according to the book <em>The Big Questions</em> which I was recently reading, economists John Geanakoplos and Herakles Polemarchakis proved that the discussion could not go on and on forever - in other words there must be an eventual agreement. Even furthermore, computer scientist Scott Aaronson proved, that if both of the two are <em>truthful/honest</em>, the discussion could end in just a few rounds.</p>
<p>It might be doubted that the condition of the two people to have "same priors" is too strict a condition to hold true. After all, not all the "rational people" we come across in life have made in-depth analysis on soccer theory; perhaps the two of them have different view on the importance of Messi in his team. However, it seems that the inconsistency in the "priors" can be resolved during the discussion. We can therefore say, that two truthful and rational persons should have the same opinion on the same issues. If the discussion ends in disagreement, at least one person must be untruthful!</p>
<p>I did a bit of research on this topic, and found that this theorem has a lot of inferences. For example, a "rational" person, if he believes others are all also "rational", he shouldn't buy stocks (as in in the stock market). Why? Because if he is to buy some stock, he must be buying it from someone who is selling it - this means that the seller and he have different expectations of the value of the stock - which Aumann has proved within assumptions to be impossible to happen.</p>
<p>The "rational" people that were hypothesized in the theorem are referred to by academics as "Truthseekers". If we are honest Truthseekers, we can eventually reach a consensus.</p>
<hr />
<p>Some off-topic talk at last: while a lot of people consider that scientific research is <em>predominantly</em> a <em>rivalry</em> between man and nature, scientific research in reality has got a lot to deal with among people too - not meaning <em>bureaucratism</em> or <em>workplace politics</em>, but instead <em>disapproval</em> between researchers themselves due to different viewpoints regarding a certain academic/research topic. In a way, submitting research work to top academic periodicals are like fighting a war. The so-called "peer review" is really the editor finding a few other researchers in the same field as you to examine your article. The bad new is, that this bunch of researchers are sometimes just like you in the way how you think you're the only one who is qualified to publish an article on that periodical. If they directly state that your findings are not important enough to deserve to be published, you're pretty much game-over. However, if they claim some of your work is incorrect, it's more of a good news, because it's often <em>they</em> who have made the mistake.</p>
<p>You need to write a pleading, proving that the peer-reviewers have made a mistake. After that, there might appear a miracle that  is only possible in the academia: the reviewer admits his mistake, changes <em>how he thinks</em>, and allows for the publishing of your article.</p>
<p><em>Unless proven to be utterly wrong, the average person would very unlikely (spontaneously) admit his mistake.</em> After a <em>everyday-type-of</em> argument, no one would say "oh you're right, I have been thinking in the wrong way for all this time!"However, scientists would do just that. It seems true that scientists will form cliques, hold all sorts of bias, or take pleasure from proving others wrong; yet all scientists have one merit in common: he allows you to change the way he <em>thinks</em>. This atmosphere of allowing others to change your way of thinking can stimulate people to take on a more courageous attitude when being reviewed.</p>
<p>Why? Because scientists are Truthseekers. In fact, one joy in scientific research is to let others change your beliefs and way of thinking!</p>
